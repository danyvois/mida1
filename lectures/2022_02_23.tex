%!TEX root = ../main.tex
\textbf{Variance.}
\begin{align*}
	\gamma (0)&=\E[(y(t)-m_{y})(y(t)-m_{y})]=\E[(y(t))^2]\\
	&=\E[(c_{0} e(t)+c_{1} e(t-1)+\cdots+c_{n} e(t-n))^{2}]\\
	&=\E[c_{0}^{2} e(t)^{2}+\cdots+c_{n}^{2} e(t-n)^{2}\\
	&\qquad+2 c_{0} c_{1} e(t) e(t-1)+\cdots+2 c_{n-1} c_{n} e(t-n-1) e(t-n)]\\
	&=c_{0}^{2} \E[e(t)^{2}]+c_{1}^{2} \E[e(t-1)^{2}]+\cdots+c_{n}^{2} \E[e(t-n)^{2}]\\
	&\qquad+2 c_{0} c_{1} \E[e(t) e(t-1)]+\cdots+2 c_{n-1} c_{n} \E[e(t-n-1) e(t-n)]
\end{align*}

Since $e(t) \sim \WN(0, \lambda^{2})$, we have that:
$$
\E[e(t)^{2}]=\E[e(t-1)^{2}]=\cdots=\E[e(t-n)^{2}]=\lambda^{2}
$$
and that
$$
\E[e(t) e(t-1)] = \E[e(t-1) e(t-2)] = \cdots = \E[e(t-n-1) e(t-n)]=0
$$
thus
\[
	\boxed{\gamma (0)=(c_{1}^2 +c_{1}^2 +\cdots+c_{n}^2 )\cdot\lambda^2}
\]
hence $\gamma (0)$ doesn't depend on $t$.

\textbf{Covariance.}

To compute the generic covariance, let us proceed with $\tau =1$.
\begin{align*}
	\gamma(1)&=\E[(y(t)-m_{y})(y(t-1)-m_{y})]\\
	&=\E[y(t) y(t-1)]\\
	&=\E[(c_{0} e(t)+c_{1} e(t-1)+\cdots+c_{n} e(t-n))\cdot (y(t-1))]\\
	&=\E[(c_{0} e(t)+c_{1} e(t-1)+\cdots+c_{n} e(t-n))\cdot (c_{0} e(t-1)+\cdots+c_{n-1} e(t-n)+c_{n} e(t-n-1))]
\end{align*}

Only those terms where the \gls{wn} is multiplied by itself at the same time instant are non null.
\[
	\gamma (1)=(c_{0}c_{1}+c_{1}c_{2}+\cdots+c_{n-1}c_{n})\cdot\lambda^2
\]
hence $\gamma (1)$ doesn't depend on $t$.

Similarly
\begin{align*}
	\gamma (2) &= (c_{0}c_{2}+c_{1}c_{3}+\cdots+c_{n-2}c_{n})\cdot\lambda^2\\
	&\vdots\\
	\gamma (n) &= (c_{0}c_{n})\cdot\lambda^2\\
	\gamma (n+1) &= 0
\end{align*}
since all products are uncorrelated. In conclusion
\[
	\boxed{
		\gamma (\tau )=\begin{cases}
			(c_{1}^2 +c_{1}^2 +\cdots+c_{n}^2 )\cdot\lambda^2, & \text{if}\ \tau =0;\\
			(c_{0}c_{1}+c_{1}c_{2}+\cdots+c_{n-1}c_{n})\cdot\lambda^2, & \text{if}\ \tau =\pm 1;\\
			(c_{0}c_{2}+c_{1}c_{3}+\cdots+c_{n-2}c_{n})\cdot\lambda^2, & \text{if}\ \tau =\pm 2;\\
			\quad\vdots\\
			(c_{0}c_{n})\cdot\lambda^2, & \text{if}\ \tau =\pm n;\\
			0, & \text{if}\ |\tau| > \pm n.\\
		\end{cases}
	}
\]
\subsection{MA(\texorpdfstring{$\infty$}{infinity}) processes}

\begin{defn}
	Let $e(t) \sim \WN(0, \lambda^{2})$. A \textbf{\gls{ma}}($\infty$) process is obtained as:
	\[
		\boxed{y(t)=c_{0} e(t)+c_{1} e(t-1)+\cdots+c_{i} e(t-i)+\cdots=\sum_{i=0}^{\infty} c_{i} e(t-i)}
	\]
	under the assumption that:
	\[
		\sum_{i=0}^{\infty} (c_{i})^{2}<\infty
	\]
\end{defn}

\textbf{Mean.}
\[
	m_{y}(t)=\E[y(t)]=\E\left[\sum_{i=0}^{\infty} c_{i} e(t-i)\right]=\sum_{i=0}^{\infty} c_{i} \E[e(t-i)]=\sum_{i=0}^{\infty} (c_{i} \cdot 0) =0
\]
doesn't depend on $t$.

\textbf{Variance.}
\begin{align*}
	\gamma_{y}(0)&=\E[(y(t)-m_{y})^{2}]\\
	&=\E\left[\sum_{i=0}^{\infty} c_{i} e(t-i) \cdot \sum_{j=0}^{\infty} c_{j} e(t-j)\right]\\
	&=\E\left[\sum_{i, j=0}^{\infty} c_{i} c_{j} \cdot e(t-i) e(t-j)\right]\\
	&=\sum_{i, j=0}^{\infty} c_{i} c_{j} \cdot \E[e(t-i) e(t-j)]\\
	&=\{\text{non null only when }i=j\}\\
	&=\sum_{i=0}^{\infty} c_{i}^2 \cdot\lambda^2 
\end{align*}
doesn't depend on $t$.

\textbf{Covariance.}
\begin{align*}
	\gamma_{y}(\tau) &=\E[(y(t)-m_{y}) (y(t-\tau)-m_{y})]\\
	&=\E[y(t) y(t-\tau)]\\
	&=\E\left[\sum_{i=0}^{\infty} c_{i} e(t-i) \cdot \sum_{j=0}^{\infty} c_{j} e(t-j-\tau)\right]\\
	&=\E\left[\sum_{i, j=0}^{\infty} c_{i} c_{j} \cdot e(t-i) e(t-j-\tau)\right]\\
	&=\sum_{i, j=0}^{\infty} c_{i} c_{j} \cdot \E[e(t-i) e(t-j-\tau)]\\
	&=\{\text{non null only when }i=j+\tau\}\\
	&=\sum_{j=0}^{\infty} c_{j+\tau}c_{j}\cdot\lambda^2 
\end{align*}
doesn't depend on $t$.

Since $\sum_{i=0}^{\infty} c_{i}^{2}<\infty$, the MA($\infty $) process is well defined and is an \gls{ssp}.

\begin{rem}
MA($\infty$) processes are very general, they almost \emph{cover} the class of \glspl{ssp} (i.e. apart from few exceptions, all \glspl{ssp} can be written as MA($\infty$), we say that they admit an MA($\infty$) representation).

However, MA($\infty$) are difficult to handle since there are infinite coefficients and, moreover, the computation of the covariance function requires the computation of the sum of an infinite series (hard in general).

On the other hand, MA($n$) are too limited, that is why we will look into AR and ARMA models.
\end{rem}